DAY 0 --repo created and initial problems added.
Goal: 30 advanced problems in Python and SQL.

DAY 1 -- Python Logic + SQL Queries.
- Started with logic-focused Python practice: built a transaction summary function to separate income and expenses.
- Used dictionaries and learned to print formatted results using f-strings.
- Created SQL tables (`sales`, `custmer`) and practiced `JOIN`, `GROUP BY`, and aggregate functions.
- Faced issues with query structure â€” learned that aliases and aggregates must be used carefully.
- Goal for Day 2: Build a data analysis challenge combining both â€” clean data in Python, analyze results with SQL.

ðŸ“… Day 2 â€” Expense Tracker Insights

Focused on translating business logic into Python and SQL.

Built an Expense Tracker that separates income & expenses, calculates totals, and finds top 3 spending categories.

Strengthened understanding of loops, dictionaries, conditional logic, and formatted output with f-strings.

In SQL, practiced JOIN, GROUP BY, and HAVING clauses to mirror Python logic at the database level.

Faced challenges managing nested loops and aliasing in SQL; solved them by rewriting from the output backward.

Takeaway: Thinking in steps before coding gives clarity â€” syntax follows logic.

Next Goal: Integrate small visualizations with Matplotlib for every analytical script

ðŸ“… Day 3 â€” Sales Analysis

Shifted from basic logic to data-driven analysis using Pandas and SQL window functions.

Cleaned and validated data types, calculated regional & customer totals, and identified top performers.

Learned to use groupby, aggregation, ranking, and sorting for insight generation.

Practiced RANK(), DENSE_RANK(), and ROW_NUMBER() in SQL to replicate analytical behavior across tools.

Improved code readability through function-based design (clean_and_describe, totals_and_top_customers, etc.).

Takeaway: Real analysis comes from combining technical logic + business context.

Next Goal: Start automating summaries and exports (CSV / dashboard snippets).

### ðŸ“… Day 4 â€” Mini Automation: Clean & Export Reports
- Built a small, reusable cleaning pipeline using pandas to standardize columns, handle missing values, and coerce types.
- Generated export-ready reports: `sales_by_region.csv`, `top_customers_by_sales.csv`, and `monthly_summary.csv`.
- Verified results with a simple bar chart to ensure visual sanity checks before sharing reports.
- Implemented the same logic in SQL queries to keep parity between data engineering and analytics layers.
- **Takeaway:** Automating cleaning + export reduces manual errors and makes routine reporting reproducible. Next: schedule the pipeline and add basic logging & tests.

